{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT trofi.ipynb","provenance":[{"file_id":"1Xqj6v51N8iD7oKOR3FzrVs1cfvZz60X3","timestamp":1647398319185},{"file_id":"1WhW5xTm0NhlkNEqPQH33gBTo_sNcMpsc","timestamp":1647395680304}],"collapsed_sections":[],"authorship_tag":"ABX9TyOw1p49S9C9Tqp1/461WIYg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0f15de7dc7914559b560042e74e813e4":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b3d6fe4819de4330ad051c5acc5f8e4c","IPY_MODEL_e763c97784d744729c8595d44be5aa45","IPY_MODEL_6be6af7ed8384114878a0ec653c86ae6","IPY_MODEL_ff108680bd444186b383f0e096d5dee2","IPY_MODEL_474cc7f5ad674aa1ac10b32ed381c565"],"layout":"IPY_MODEL_0d6e6b7bde3143a69d173688505531fa"}},"b3d6fe4819de4330ad051c5acc5f8e4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ade5b2c5a43d4a83a99956d4b0abc525","placeholder":"​","style":"IPY_MODEL_acd02318e0cd40e5969d02bd6654799a","value":"<center>\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.svg alt='Hugging Face'>\n<br>\nCopy a token from <a href=\"https://huggingface.co/settings/token\" target=\"_blank\">your Hugging Face tokens page</a> and paste it below.\n<br>\nImmediately click login after copying your token or it might be stored in plain text in this notebook file.\n</center>"}},"e763c97784d744729c8595d44be5aa45":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_286d87ac93644c89b06d7b84ed9d8f35","placeholder":"​","style":"IPY_MODEL_87659f8dc07a487994a60e917ac78471","value":""}},"6be6af7ed8384114878a0ec653c86ae6":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_b28c49df294247fd8541d2edce052863","style":"IPY_MODEL_fc46582386df46e684d956dc119b5b3f","tooltip":""}},"ff108680bd444186b383f0e096d5dee2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_823d12e5b7b24f419bebe3308012500a","placeholder":"​","style":"IPY_MODEL_aa6e5882f8984971b172e531a7226d59","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated 'notebooks' token with 'write' access, that you can then easily reuse for all notebooks.\n<br>\n<i>Logging in with your username and password is deprecated and won't be possible anymore in the near future. You can still use them for now by clicking below.</i>\n</center>"}},"474cc7f5ad674aa1ac10b32ed381c565":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Use password","disabled":false,"icon":"","layout":"IPY_MODEL_9b44535ec4664e3f981844c01d0d7799","style":"IPY_MODEL_7eb5bbaa28274332b7a13691a0705d74","tooltip":""}},"0d6e6b7bde3143a69d173688505531fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"ade5b2c5a43d4a83a99956d4b0abc525":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acd02318e0cd40e5969d02bd6654799a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"286d87ac93644c89b06d7b84ed9d8f35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87659f8dc07a487994a60e917ac78471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b28c49df294247fd8541d2edce052863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc46582386df46e684d956dc119b5b3f":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"823d12e5b7b24f419bebe3308012500a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa6e5882f8984971b172e531a7226d59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b44535ec4664e3f981844c01d0d7799":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb5bbaa28274332b7a13691a0705d74":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"7f5f2d9f1c7045e6ac03b8c7806d112b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5449a2a711394943b3c05084af089a68","IPY_MODEL_e7a4bab0144e426fad0a24676fecbd3e","IPY_MODEL_4a74a83032d545e0bf75fecb0744b01a"],"layout":"IPY_MODEL_0a1d747dc74b4cc6a8a105067c282327"}},"5449a2a711394943b3c05084af089a68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae04ecb267747df9c45eebd3450fbbe","placeholder":"​","style":"IPY_MODEL_788fdcc63a574f53b185bcbcc4c8ba15","value":"100%"}},"e7a4bab0144e426fad0a24676fecbd3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_64a53a0717474438b0d32567ac5ad989","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0899d0ff927e439aa1a3c00d2ba5c532","value":1}},"4a74a83032d545e0bf75fecb0744b01a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db2c74631a4b48b2a52a324b239e6e9c","placeholder":"​","style":"IPY_MODEL_d0a39ada876e4c958df112de9863800b","value":" 1/1 [00:00&lt;00:00,  2.07ba/s]"}},"0a1d747dc74b4cc6a8a105067c282327":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cae04ecb267747df9c45eebd3450fbbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788fdcc63a574f53b185bcbcc4c8ba15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64a53a0717474438b0d32567ac5ad989":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0899d0ff927e439aa1a3c00d2ba5c532":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db2c74631a4b48b2a52a324b239e6e9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0a39ada876e4c958df112de9863800b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d649be2dffd4483984048d24e0935d7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_87254d0286c44d20815c6f4aea961dc1","IPY_MODEL_de6ed80fd4b541ca9302f846cdfc413c","IPY_MODEL_7da7e3c238d140439c0f679c1a99050c"],"layout":"IPY_MODEL_bf08e1ccce5344e898333b1145a0dea9"}},"87254d0286c44d20815c6f4aea961dc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c269ead52dd24aba8f96bf98820cec1c","placeholder":"​","style":"IPY_MODEL_f5c025c94f2c4400ae08410f2089194c","value":"100%"}},"de6ed80fd4b541ca9302f846cdfc413c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff20cf8192e84f5a9f7945b0c637b50f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e448c5116bb945328e00ed023b52a566","value":2}},"7da7e3c238d140439c0f679c1a99050c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66808c6d9b43463c97dea162857a2fc3","placeholder":"​","style":"IPY_MODEL_2e6f3705785d4188832eb8c8f97c4797","value":" 2/2 [00:00&lt;00:00,  3.86ba/s]"}},"bf08e1ccce5344e898333b1145a0dea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c269ead52dd24aba8f96bf98820cec1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5c025c94f2c4400ae08410f2089194c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff20cf8192e84f5a9f7945b0c637b50f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e448c5116bb945328e00ed023b52a566":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"66808c6d9b43463c97dea162857a2fc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e6f3705785d4188832eb8c8f97c4797":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bde61b14d5c4232bd785bd20f846ed2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d27d4a22ca704acb92a526fec679abdf","IPY_MODEL_c73f7c43f77c4b2bb311f5ce0c97d995","IPY_MODEL_54bd4516847a45bbb4ec91c86c803950"],"layout":"IPY_MODEL_9ec3c5687414451683705e5fa7293143"}},"d27d4a22ca704acb92a526fec679abdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93198a804b6b4cc3ab37c0ad5e1ba7d8","placeholder":"​","style":"IPY_MODEL_4213e62f1f3e4460a4409e041bd0a7f8","value":"100%"}},"c73f7c43f77c4b2bb311f5ce0c97d995":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb0c6118ed324ce1a0bca7f06a670519","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8092a21839c4a3cadbf1c1134339c79","value":1}},"54bd4516847a45bbb4ec91c86c803950":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f82ee4007f01498fa3fa18a539323f24","placeholder":"​","style":"IPY_MODEL_378dc3f66b1f4d7eb8d653fe9ab61e88","value":" 1/1 [00:00&lt;00:00,  3.49ba/s]"}},"9ec3c5687414451683705e5fa7293143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93198a804b6b4cc3ab37c0ad5e1ba7d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4213e62f1f3e4460a4409e041bd0a7f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb0c6118ed324ce1a0bca7f06a670519":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8092a21839c4a3cadbf1c1134339c79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f82ee4007f01498fa3fa18a539323f24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"378dc3f66b1f4d7eb8d653fe9ab61e88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Some Boilerplate stuff"],"metadata":{"id":"o1uel4d_Vnkv"}},{"cell_type":"code","source":["# You may prefer to upload the data to your google drive and mount your google drive to this colab, \n","# because the data will be erased if you stop using this colab for a while.\n","# Uncomment the code below to do so. After mounting, navigate to the appropriate folder, right click, and \"copy path\".\n","# Assign DATA_DIR global variable to that path.\n","# For more mounting instructions: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=XDg9OBaYqRMd\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qgI8q1g2EQml","executionInfo":{"status":"ok","timestamp":1647567916154,"user_tz":300,"elapsed":24645,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"eebfea56-c238-4ec9-fcbb-187def316d40"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# If imported from google drive, config for your file directory. Mine is 'lm_data'.\n","DATA_DIR = \"./drive/MyDrive/nlp-final-project/data\"\n","\n","# the goal is that DATA_DIR points to where the training/validation/test data is. "],"metadata":{"id":"rqlFllDTh_cP","executionInfo":{"status":"ok","timestamp":1647567919019,"user_tz":300,"elapsed":269,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"b5KxdUqWC67y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647567941807,"user_tz":300,"elapsed":20638,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"464307c2-35e5-4eda-9e57-6568a4a717d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n","\u001b[K     |████████████████████████████████| 325 kB 4.3 MB/s \n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 48.6 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 47.4 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 50.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.2)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 42.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 51.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.1 MB/s \n","\u001b[?25hCollecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 29.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 38.8 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 40.7 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=25813ec41dbe8b6218c6fc58e0d2a976a836acfe3d7d23c0841fc33e22a20f68\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built seqeval\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, responses, huggingface-hub, transformers, seqeval, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.2.0 huggingface-hub-0.4.0 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 seqeval-1.2.2 tokenizers-0.11.6 transformers-4.17.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["! pip install datasets transformers seqeval"]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"id":"KONgMkYkVpTF","colab":{"base_uri":"https://localhost:8080/","height":386,"referenced_widgets":["0f15de7dc7914559b560042e74e813e4","b3d6fe4819de4330ad051c5acc5f8e4c","e763c97784d744729c8595d44be5aa45","6be6af7ed8384114878a0ec653c86ae6","ff108680bd444186b383f0e096d5dee2","474cc7f5ad674aa1ac10b32ed381c565","0d6e6b7bde3143a69d173688505531fa","ade5b2c5a43d4a83a99956d4b0abc525","acd02318e0cd40e5969d02bd6654799a","286d87ac93644c89b06d7b84ed9d8f35","87659f8dc07a487994a60e917ac78471","b28c49df294247fd8541d2edce052863","fc46582386df46e684d956dc119b5b3f","823d12e5b7b24f419bebe3308012500a","aa6e5882f8984971b172e531a7226d59","9b44535ec4664e3f981844c01d0d7799","7eb5bbaa28274332b7a13691a0705d74"]},"executionInfo":{"status":"ok","timestamp":1647568061076,"user_tz":300,"elapsed":6331,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"292cf7d3-1300-4077-8284-93fd4de1ebdb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}]},{"cell_type":"code","source":["!apt install git-lfs"],"metadata":{"id":"ldGW8iCIVpdR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647568078394,"user_tz":300,"elapsed":8417,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"bf540515-6b74-4061-d2cc-7ce6ff79fa35"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  git-lfs\n","0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 2,129 kB of archives.\n","After this operation, 7,662 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n","Fetched 2,129 kB in 2s (970 kB/s)\n","Selecting previously unselected package git-lfs.\n","(Reading database ... 155335 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n","Unpacking git-lfs (2.3.4-1) ...\n","Setting up git-lfs (2.3.4-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","source":["import transformers\n","\n","print(transformers.__version__)"],"metadata":{"id":"C5mHoFRCV6Np","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647568082795,"user_tz":300,"elapsed":271,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"ad46de22-aef4-4e81-c77f-71ec24bfb2a8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["4.17.0\n"]}]},{"cell_type":"code","source":["model_checkpoint = \"bert-base-uncased\"\n","\n","batch_size = 16"],"metadata":{"id":"GRi4Hq34DlAI","executionInfo":{"status":"ok","timestamp":1647568084240,"user_tz":300,"elapsed":2,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Loading Data"],"metadata":{"id":"4s228xvCV68y"}},{"cell_type":"code","source":["import csv\n","import ast\n","from datasets import Dataset, load_metric, DatasetDict\n","import numpy as np\n","import random\n","\n","# Get raw datasets\n","'''\n","1.1 VUA\n","get raw dataset as a list:\n","  Each element is a triple:\n","    a sentence: string\n","    a list of labels: \n","    a list of pos: \n","'''\n","inputs = []\n","with open(f'{DATA_DIR}/TROFI/TroFi_formatted_all3737.csv', encoding='latin-1') as f:\n","    lines = csv.reader(f)\n","    next(lines)\n","    for line in lines:\n","        input = {}\n","        input[\"tokens\"] = line[1].split()\n","        index = int(line[2])\n","        label = int(line[3])\n","        labels = [0] * len(input[\"tokens\"])\n","        labels[index] = label\n","        input[\"labels\"] = labels\n","        inputs.append(input)\n","random.shuffle(inputs)\n","train_val, test = np.split(np.array(inputs), [int(len(inputs)/2)])\n","train, val = np.split(np.array(train_val), [int(len(train_val)/2)])\n","print(train.shape)\n","print(val.shape)\n","print(test.shape)\n","\n","raw_train_vua = {}\n","raw_train_vua[\"tokens\"] = []\n","raw_train_vua[\"tags\"] = []\n","for item in train:\n","    raw_train_vua[\"tokens\"].append(item[\"tokens\"])\n","    raw_train_vua[\"tags\"].append(item[\"labels\"])\n","\n","raw_val_vua = {}\n","raw_val_vua[\"tokens\"] = []\n","raw_val_vua[\"tags\"] = []\n","for item in val:\n","    raw_val_vua[\"tokens\"].append(item[\"tokens\"])\n","    raw_val_vua[\"tags\"].append(item[\"labels\"])\n","\n","raw_test_vua = {}\n","raw_test_vua[\"tokens\"] = []\n","raw_test_vua[\"tags\"] = []\n","for item in test:\n","    raw_test_vua[\"tokens\"].append(item[\"tokens\"])\n","    raw_test_vua[\"tags\"].append(item[\"labels\"])\n","\n","dataset_dict = {}\n","dataset_dict[\"train\"] = Dataset.from_dict(raw_train_vua)\n","dataset_dict[\"test\"] = Dataset.from_dict(raw_test_vua)\n","dataset_dict[\"validation\"] = Dataset.from_dict(raw_val_vua)\n","\n","datasets = DatasetDict(dataset_dict)"],"metadata":{"id":"8y_F6UW4WjLV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647570685960,"user_tz":300,"elapsed":808,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"afdc87b5-f810-4549-f5d6-065095fc3658"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["(934,)\n","(934,)\n","(1869,)\n"]}]},{"cell_type":"code","source":["print(datasets[\"train\"][\"tokens\"][0])\n","print(datasets[\"train\"][\"tags\"][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFsJOMuM16CR","executionInfo":{"status":"ok","timestamp":1647570698916,"user_tz":300,"elapsed":280,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"5dfa8804-bb64-45c6-df9f-cc67e99b4ec8"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["['His', 'boss', 'saw', 'it', 'as', 'insubordination', 'and', 'kicked', 'Mr.', 'Arnold', 'out']\n","[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYDACfCnszTP","executionInfo":{"status":"ok","timestamp":1647570715843,"user_tz":300,"elapsed":7039,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"d64e3b54-937b-4377-e416-eb4c7d60ee51"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}]},{"cell_type":"code","source":["label_all_tokens = True"],"metadata":{"id":"7L3Jh9d7yetU","executionInfo":{"status":"ok","timestamp":1647570715843,"user_tz":300,"elapsed":2,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples[f\"tags\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:\n","            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","            # ignored in the loss function.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            # We set the label for the first token of each word.\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label[word_idx])\n","            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","            # the label_all_tokens flag.\n","            else:\n","                label_ids.append(label[word_idx] if label_all_tokens else -100)\n","            previous_word_idx = word_idx\n","\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"],"metadata":{"id":"2VqUOL1_voJ2","executionInfo":{"status":"ok","timestamp":1647568117365,"user_tz":300,"elapsed":2,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["7f5f2d9f1c7045e6ac03b8c7806d112b","5449a2a711394943b3c05084af089a68","e7a4bab0144e426fad0a24676fecbd3e","4a74a83032d545e0bf75fecb0744b01a","0a1d747dc74b4cc6a8a105067c282327","cae04ecb267747df9c45eebd3450fbbe","788fdcc63a574f53b185bcbcc4c8ba15","64a53a0717474438b0d32567ac5ad989","0899d0ff927e439aa1a3c00d2ba5c532","db2c74631a4b48b2a52a324b239e6e9c","d0a39ada876e4c958df112de9863800b","d649be2dffd4483984048d24e0935d7b","87254d0286c44d20815c6f4aea961dc1","de6ed80fd4b541ca9302f846cdfc413c","7da7e3c238d140439c0f679c1a99050c","bf08e1ccce5344e898333b1145a0dea9","c269ead52dd24aba8f96bf98820cec1c","f5c025c94f2c4400ae08410f2089194c","ff20cf8192e84f5a9f7945b0c637b50f","e448c5116bb945328e00ed023b52a566","66808c6d9b43463c97dea162857a2fc3","2e6f3705785d4188832eb8c8f97c4797","8bde61b14d5c4232bd785bd20f846ed2","d27d4a22ca704acb92a526fec679abdf","c73f7c43f77c4b2bb311f5ce0c97d995","54bd4516847a45bbb4ec91c86c803950","9ec3c5687414451683705e5fa7293143","93198a804b6b4cc3ab37c0ad5e1ba7d8","4213e62f1f3e4460a4409e041bd0a7f8","bb0c6118ed324ce1a0bca7f06a670519","a8092a21839c4a3cadbf1c1134339c79","f82ee4007f01498fa3fa18a539323f24","378dc3f66b1f4d7eb8d653fe9ab61e88"]},"id":"pE3ygyOD3cxi","executionInfo":{"status":"ok","timestamp":1647570721743,"user_tz":300,"elapsed":2109,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"84f4017b-8453-494f-f608-e3adc2705099"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f5f2d9f1c7045e6ac03b8c7806d112b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d649be2dffd4483984048d24e0935d7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bde61b14d5c4232bd785bd20f846ed2"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Train model"],"metadata":{"id":"zhG70E6FBiM5"}},{"cell_type":"code","source":["from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ocNMvGcBsI-","executionInfo":{"status":"ok","timestamp":1647570747813,"user_tz":300,"elapsed":4957,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"b53982b8-d832-4cba-d114-b4e64973a3d1"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model_name = model_checkpoint.split(\"/\")[-1]\n","args = TrainingArguments(\n","    f\"bert-lets-go\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    push_to_hub=False,\n",")"],"metadata":{"id":"7p8sHRhOmFJ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647570747814,"user_tz":300,"elapsed":9,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"c7bf4a0f-6fba-4eed-facb-f4f2b541250b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer)"],"metadata":{"id":"vPoR8zY-mGLr","executionInfo":{"status":"ok","timestamp":1647570754700,"user_tz":300,"elapsed":275,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["metric = load_metric(\"seqeval\")"],"metadata":{"id":"fsepeU9qmILR","executionInfo":{"status":"ok","timestamp":1647570758420,"user_tz":300,"elapsed":1227,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","label_list = [\"O\", \"I\"]\n","def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": results[\"overall_precision\"],\n","        \"recall\": results[\"overall_recall\"],\n","        \"f1\": results[\"overall_f1\"],\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"],"metadata":{"id":"e3w71pW8mLb4","executionInfo":{"status":"ok","timestamp":1647570761282,"user_tz":300,"elapsed":584,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"pohpVvEwmPfx","executionInfo":{"status":"ok","timestamp":1647570763182,"user_tz":300,"elapsed":397,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"id":"9v-FnoGbmScU","outputId":"4cd28923-ebf0-45c9-b397-602a78eebf51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 934\n","  Num Epochs = 30\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1770\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='178' max='1770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 178/1770 01:28 < 13:16, 2.00 it/s, Epoch 3/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.040736</td>\n","      <td>1.000000</td>\n","      <td>0.007143</td>\n","      <td>0.014184</td>\n","      <td>0.985022</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.030773</td>\n","      <td>0.570025</td>\n","      <td>0.552381</td>\n","      <td>0.561064</td>\n","      <td>0.987080</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='31' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [31/59 00:03 < 00:03, 8.32 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 934\n","  Batch size = 16\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 934\n","  Batch size = 16\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 934\n","  Batch size = 16\n"]}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"lCmSVUulmUal","executionInfo":{"status":"ok","timestamp":1647569193217,"user_tz":300,"elapsed":9129,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"e871f56b-2df2-4994-d6f5-835cb71a5b78"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 934\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [59/59 00:07]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 30.0,\n"," 'eval_accuracy': 0.9889384183589236,\n"," 'eval_f1': 0.5725593667546175,\n"," 'eval_loss': 0.07984669506549835,\n"," 'eval_precision': 0.6326530612244898,\n"," 'eval_recall': 0.5228915662650603,\n"," 'eval_runtime': 8.7326,\n"," 'eval_samples_per_second': 106.955,\n"," 'eval_steps_per_second': 6.756}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["# Evaluate model"],"metadata":{"id":"PPRm9rTTBskD"}},{"cell_type":"code","source":["predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n","predictions = np.argmax(predictions, axis=2)\n","\n","label_list = [\"O\", \"I\"]\n","true_predictions = [\n","    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]\n","true_labels = [\n","    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]\n","\n","results = metric.compute(predictions=true_predictions, references=true_labels)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"98sprjaZPgz4","executionInfo":{"status":"ok","timestamp":1647569247874,"user_tz":300,"elapsed":19050,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"5d716854-ce01-4612-d2a4-d6396c00857b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 1869\n","  Batch size = 16\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='176' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [59/59 00:59]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'_': {'precision': 0.593103448275862, 'recall': 0.5422446406052963, 'f1': 0.5665349143610012, 'number': 793}, 'overall_precision': 0.593103448275862, 'overall_recall': 0.5422446406052963, 'overall_f1': 0.5665349143610012, 'overall_accuracy': 0.9884886865888252}\n"]}]},{"cell_type":"code","source":["print(predictions)\n","print(labels)\n","\n","result = []\n","words = []\n","for ids in tokenized_datasets[\"test\"][\"input_ids\"]:\n","    words.append(tokenizer.convert_ids_to_tokens(ids))\n","for i in range(len(true_labels)):\n","    result_entry_list = []\n","    for j in range(len(true_predictions[i])):\n","        result_entry_list.append(f\"{words[i][j+1]}({true_predictions[i][j]} {true_labels[i][j]})\")\n","    result_entry = \" \".join(result_entry_list)\n","    result_entry = f\"{result_entry}\\n\\n\"\n","    result.append(result_entry)\n","\n","f = open(f'{DATA_DIR}/predictions/trofi_seq_test_predictions_BERTsequence_vua.txt', 'w+')\n","f.writelines(result)\n","f.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBSGRMhqR8-p","executionInfo":{"status":"ok","timestamp":1647569249923,"user_tz":300,"elapsed":2052,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"ccc70d12-4218-4d91-a00f-3fe655783a85"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","[[-100    0    0 ... -100 -100 -100]\n"," [-100    0    0 ... -100 -100 -100]\n"," [-100    0    0 ... -100 -100 -100]\n"," ...\n"," [-100    0    0 ... -100 -100 -100]\n"," [-100    0    0 ... -100 -100 -100]\n"," [-100    0    0 ... -100 -100 -100]]\n"]}]},{"cell_type":"markdown","source":["# Detokenization"],"metadata":{"id":"ka5EqQjOx5e0"}},{"cell_type":"code","source":["predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n","predictions = np.argmax(predictions, axis=2)\n","\n","label_list = [\"O\", \"I\"]\n","true_predictions = [\n","    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]\n","true_labels = [\n","    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","    for prediction, label in zip(predictions, labels)\n","]"],"metadata":{"id":"LyiMT6Q1x69u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detokenize(examples, predictions, labels):\n","    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","    tokens = examples[\"tokens\"]\n","    re_preds = []\n","    re_labels = []\n","    for i in range(len(examples[f\"tags\"])):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)\n","        previous_word_idx = None\n","        re_pred = [\"O\"] * len(tokens[i])\n","        re_label = [\"O\"] * len(tokens[i])\n","        for j, word_idx in enumerate(word_ids):\n","            if j >= len(labels[i]):\n","                break\n","            if word_idx is None:\n","                continue\n","            else:\n","                if labels[i][j] == 'I':\n","                    re_label[word_idx] = \"I\"\n","                if predictions[i][j] == 'I':\n","                    re_pred[word_idx] = \"I\"\n","        re_labels.append(re_label)\n","        re_preds.append(re_pred)\n","    return (re_preds, re_labels)"],"metadata":{"id":"f5U6_EQgx9wg","executionInfo":{"status":"ok","timestamp":1647569280870,"user_tz":300,"elapsed":852,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["re_preds, re_labels = detokenize(datasets[\"test\"], true_predictions, true_labels)\n","\n","results = metric.compute(predictions=re_preds, references=re_labels)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEkzH245x_0Y","executionInfo":{"status":"ok","timestamp":1647570028346,"user_tz":300,"elapsed":2872,"user":{"displayName":"Wesley Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978522409599816257"}},"outputId":"894ff70e-7137-45e6-df95-be24059dcdad"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["{'_': {'precision': 0.5983379501385041, 'recall': 0.544766708701135, 'f1': 0.5702970297029704, 'number': 793}, 'overall_precision': 0.5983379501385041, 'overall_recall': 0.544766708701135, 'overall_f1': 0.5702970297029704, 'overall_accuracy': 0.987222721822542}\n"]}]}]}